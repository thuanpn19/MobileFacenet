{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from test_utils import get_feature, load_model\n",
    "from tqdm import tqdm\n",
    "from deepface import DeepFace\n",
    "import random\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from PIL import Image\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(vector1, vector2):\n",
    "    dot_product = np.dot(vector1, vector2)\n",
    "    norm_vector1 = np.linalg.norm(vector1)\n",
    "    norm_vector2 = np.linalg.norm(vector2)\n",
    "    \n",
    "    similarity = dot_product / (norm_vector1 * norm_vector2)\n",
    "\n",
    "    return similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def l2_distance(vector1, vector2):\n",
    "    distance = np.linalg.norm(vector1 - vector2)\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"../lfw/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detectFace(img):\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    face_objs = DeepFace.extract_faces(img_path = img, \n",
    "                                            target_size = (112, 112), \n",
    "                                            detector_backend = 'yunet', \n",
    "                                            enforce_detection=False)\n",
    "    face = face_objs[0]['face']\n",
    "    bbox = face_objs[0]['facial_area']\n",
    "    return face, bbox\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_frr(dataset_path, threshold):\n",
    "    false_refusal = 0\n",
    "    total = 0\n",
    "    frr_score = []\n",
    "    for person in tqdm(os.listdir(dataset_path)):\n",
    "        person_path = os.path.join(dataset_path, person)\n",
    "        images = os.listdir(person_path)\n",
    "        img1 = cv2.imread(os.path.join(person_path, images[0]))\n",
    "        face1, bbox1 = detectFace(img1)\n",
    "        feature1 = get_feature(model, face1)\n",
    "        for image in images[1:]:\n",
    "            img2 = cv2.imread(os.path.join(person_path, image))\n",
    "            face2, bbox2 = detectFace(img2)\n",
    "            feature2 = get_feature(model, face2)\n",
    "            dist = cosine_similarity(feature1, feature2)\n",
    "            frr_score.append(dist)\n",
    "            if dist < threshold:\n",
    "                false_refusal += 1\n",
    "            total += 1\n",
    "    frr = false_refusal / total\n",
    "    return frr, frr_score\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_far(dataset_path, threshold):\n",
    "    false_acceptance = 0\n",
    "    total = 0\n",
    "    far_score = []\n",
    "    for person in tqdm(os.listdir(dataset_path)):\n",
    "        person_path = os.path.join(dataset_path, person)\n",
    "    \n",
    "        images = os.listdir(person_path)\n",
    "        img1 = cv2.imread(os.path.join(person_path, images[0]))\n",
    "        face1, bbox1 = detectFace(img1)\n",
    "        feature1 = get_feature(model, face1)\n",
    "\n",
    "        other_images = glob(os.path.join(dataset_path, \"*/*\"))\n",
    "        # get random 5 images from other people\n",
    "        five_images = random.sample(other_images, 5)\n",
    "        for image in five_images:\n",
    "            if person == image.split(\"/\")[-2]:\n",
    "                continue\n",
    "            img2 = cv2.imread(image)\n",
    "            face2, bbox2 = detectFace(img2)\n",
    "            feature2 = get_feature(model, face2)\n",
    "            dist = cosine_similarity(feature1, feature2)\n",
    "            far_score.append(dist)\n",
    "            if dist > threshold:\n",
    "                false_acceptance += 1\n",
    "            total += 1\n",
    "    far = false_acceptance / total\n",
    "    return far, far_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='mps')"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mps_device = torch.device(\"mps\")\n",
    "mps_device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5749/5749 [15:58<00:00,  6.00it/s]  \n"
     ]
    }
   ],
   "source": [
    "frr, frr_score = test_frr(dataset_path, 0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5749/5749 [57:15<00:00,  1.67it/s]\n"
     ]
    }
   ],
   "source": [
    "far, far_score = test_far(dataset_path, 0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FRR:  0.9485569214323891\n",
      "FAR:  0.001774900814366256\n"
     ]
    }
   ],
   "source": [
    "print(\"FRR: \", frr)\n",
    "print(\"FAR: \", far)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn import metrics\n",
    "# def optimal_threshold(frr_score, far_score):\n",
    "#     Y_true = [1]*len(frr_score) + [0]*len(far_score)\n",
    "#     Y_score = frr_score + far_score\n",
    "#     assert len(Y_true) == len(Y_score)\n",
    "#     fpr, tpr, thresholds = metrics.roc_curve(Y_true,Y_score)\n",
    "#     threshold = thresholds[np.argmin(abs(tpr-(1-fpr)))]\n",
    "#     return threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "def find_threshold(inData, outData, in_low = True):\n",
    "    allData = np.concatenate((inData, outData))\n",
    "    labels = np.concatenate((np.zeros(len(inData)), np.ones(len(outData))))\n",
    "    fpr, tpr, thresholds = roc_curve(labels, allData, pos_label = in_low)\n",
    "    distances = np.sqrt(np.square(1 - tpr) + np.square(fpr))\n",
    "    best_index = np.argmin(distances)\n",
    "\n",
    "    optimal_threshold = thresholds[best_index]\n",
    "    return optimal_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25190312"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimal_threshold = find_threshold(far_score, frr_score)\n",
    "optimal_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5749/5749 [15:34<00:00,  6.15it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FRR:  0.36878674505611975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5749/5749 [56:48<00:00,  1.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAR:  0.22522616562282533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "frr, _ = test_frr(dataset_path, optimal_threshold)\n",
    "print(\"FRR: \", frr)\n",
    "\n",
    "far, _ = test_far(dataset_path, optimal_threshold)\n",
    "print(\"FAR: \", far)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FRR:  0.36878674505611975\n",
      "FAR:  0.22522616562282533\n"
     ]
    }
   ],
   "source": [
    "print(\"FRR: \", frr)\n",
    "print(\"FAR: \", far)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.02875417  0.18302968 -0.02310282  0.08957249 -0.07080924  0.10270294\n",
      "  0.07103153 -0.0265419   0.14708355  0.02778193  0.06034835  0.0718666\n",
      "  0.05690104 -0.18799436 -0.11775121 -0.09148578 -0.19917274 -0.08114896\n",
      "  0.17435133  0.05830747 -0.04905382  0.06347769  0.17613931  0.09205694\n",
      " -0.04880379 -0.04811094  0.01275891 -0.11068427  0.05892752 -0.03917056\n",
      " -0.02844682 -0.11119367 -0.02415268  0.03327522 -0.07994351 -0.01618305\n",
      " -0.09409409  0.0984084   0.1266001   0.02317806  0.02782397  0.00887924\n",
      " -0.01814869  0.06260785 -0.07531265 -0.00574741 -0.04088124 -0.01128512\n",
      "  0.0619637  -0.0173854   0.10024048 -0.00559668  0.05669412 -0.01407709\n",
      "  0.00426094 -0.09513994  0.01949965 -0.17669638  0.01132592 -0.14847592\n",
      "  0.01268391 -0.13354065  0.11224999  0.03254943  0.03158768 -0.09911004\n",
      " -0.0105359   0.023438    0.07798124 -0.07104673  0.16351186  0.08950756\n",
      "  0.02084881 -0.04554148 -0.09403953  0.0675594   0.04337565  0.11393401\n",
      " -0.07515387  0.13770904 -0.07212098  0.03692792  0.04105443 -0.07206042\n",
      " -0.25029743 -0.02171472 -0.02791726  0.11555675 -0.1021248  -0.03925953\n",
      " -0.01958281 -0.05059493 -0.06084833 -0.17681026 -0.00438201 -0.05202783\n",
      "  0.02790189  0.09608476  0.06291595 -0.00868921 -0.02846159  0.05072866\n",
      "  0.0467169  -0.0649619   0.00401863  0.22764392  0.115691   -0.03948265\n",
      "  0.05858551  0.07999983  0.09669667  0.13298368  0.03664007 -0.04570629\n",
      " -0.16426979  0.02748584 -0.15706368 -0.16423202 -0.08113484 -0.03658072\n",
      "  0.02297777  0.00831672 -0.00067258 -0.03431722 -0.14068535  0.11066345\n",
      " -0.07582065 -0.0221499 ]\n"
     ]
    }
   ],
   "source": [
    "img1 = cv2.imread('../faceData/all/30013/trung le tuan anh2.png')\n",
    "face1, bbox1 = detectFace(img1)\n",
    "feature1 = get_feature(model, face1)\n",
    "print(feature1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.02540819  0.08232027  0.13514179  0.03857974  0.00129554  0.17379831\n",
      "  0.06088528 -0.04762411  0.0067329  -0.09327266 -0.0433346   0.13426739\n",
      "  0.04556261 -0.1798195  -0.01627577 -0.01622049  0.03196425  0.01007559\n",
      "  0.04106614 -0.11299579  0.08861656  0.02189608  0.06434159  0.08054918\n",
      " -0.07806543  0.12591861 -0.06922673 -0.07399234  0.06061123 -0.04016552\n",
      " -0.0736222   0.01006695 -0.11398298 -0.08657749  0.0698527  -0.01126333\n",
      " -0.08418511  0.02214006  0.07320255  0.02537812 -0.00859671 -0.17972736\n",
      " -0.02086715  0.05421015  0.09071898  0.07568161  0.19339558  0.11683965\n",
      "  0.12500294  0.06061844  0.10713025  0.15333855 -0.07431196  0.04304335\n",
      " -0.02875019  0.00033819 -0.01615198 -0.15406917  0.07553797  0.11244022\n",
      "  0.05585319  0.01246117  0.05475994 -0.14491051  0.04159438 -0.03290727\n",
      " -0.08409759  0.28009358 -0.01369365 -0.06119802  0.05615874  0.11622646\n",
      "  0.04642806  0.08633889  0.01055305  0.14303547  0.02425816  0.16851835\n",
      " -0.03621553 -0.05905079  0.08392548 -0.02157014 -0.0383045  -0.02738523\n",
      " -0.08416579  0.11539926 -0.09103981 -0.01835522 -0.0272763  -0.00274902\n",
      " -0.07652893 -0.05505864 -0.04463381 -0.16319661 -0.0675948   0.01356062\n",
      " -0.0165711  -0.00490892 -0.02833272  0.05294775  0.14773726 -0.01975545\n",
      " -0.05183161 -0.01921838 -0.02179922  0.0902627  -0.00593241 -0.00939817\n",
      " -0.05200291 -0.00384324 -0.02728981  0.01470197  0.09391673 -0.03751967\n",
      "  0.07812983  0.05039395 -0.08056542  0.13775596 -0.11362016  0.03941115\n",
      " -0.03215748 -0.16883466 -0.15363932 -0.21192688 -0.11004147 -0.14117876\n",
      " -0.19428176  0.02502825]\n"
     ]
    }
   ],
   "source": [
    "img2 = cv2.imread('../faceData/all/10003/2022_10_18_06_40_43__2.jpg')\n",
    "face2, bbox2 = detectFace(img2)\n",
    "feature2 = get_feature(model, face2)\n",
    "print(feature2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25172397"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos = cosine_similarity(feature1, feature2)\n",
    "cos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
